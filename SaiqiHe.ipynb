{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e7786be-1fd8-407d-acd1-c14d2e895649",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-10 14:36:31.403822: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import tensorflow\n",
    "import joblib\n",
    "from os.path import exists\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.preprocessing.text import one_hot, Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding,  Bidirectional\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d3ce37-d5ca-40b2-91c0-43a7d1530baa",
   "metadata": {},
   "source": [
    "## Analyze Data\n",
    "first we analyze data, how many fields does it have, how good they are? is there balanced data or NaN in there? how many category for categorical values? etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f78b5ed4-d8b2-4809-9de8-4b4864891552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>department</th>\n",
       "      <th>salary_range</th>\n",
       "      <th>company_profile</th>\n",
       "      <th>description</th>\n",
       "      <th>requirements</th>\n",
       "      <th>benefits</th>\n",
       "      <th>telecommuting</th>\n",
       "      <th>has_company_logo</th>\n",
       "      <th>has_questions</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>required_experience</th>\n",
       "      <th>required_education</th>\n",
       "      <th>industry</th>\n",
       "      <th>function</th>\n",
       "      <th>fraudulent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Marketing Intern</td>\n",
       "      <td>US, NY, New York</td>\n",
       "      <td>Marketing</td>\n",
       "      <td></td>\n",
       "      <td>We're Food52, and we've created a groundbreaki...</td>\n",
       "      <td>Food52, a fast-growing, James Beard Award-winn...</td>\n",
       "      <td>Experience with content management systems a m...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>Internship</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Marketing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Customer Service - Cloud Video Production</td>\n",
       "      <td>NZ, , Auckland</td>\n",
       "      <td>Success</td>\n",
       "      <td></td>\n",
       "      <td>90 Seconds, the worlds Cloud Video Production ...</td>\n",
       "      <td>Organised - Focused - Vibrant - Awesome!Do you...</td>\n",
       "      <td>What we expect from you:Your key responsibilit...</td>\n",
       "      <td>What you will get from usThrough being part of...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td></td>\n",
       "      <td>Marketing and Advertising</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Commissioning Machinery Assistant (CMA)</td>\n",
       "      <td>US, IA, Wever</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Valor Services provides Workforce Solutions th...</td>\n",
       "      <td>Our client, located in Houston, is actively se...</td>\n",
       "      <td>Implement pre-commissioning and commissioning ...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Account Executive - Washington DC</td>\n",
       "      <td>US, DC, Washington</td>\n",
       "      <td>Sales</td>\n",
       "      <td></td>\n",
       "      <td>Our passion for improving quality of life thro...</td>\n",
       "      <td>THE COMPANY: ESRI – Environmental Systems Rese...</td>\n",
       "      <td>EDUCATION: Bachelor’s or Master’s in GIS, busi...</td>\n",
       "      <td>Our culture is anything but corporate—we have ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Computer Software</td>\n",
       "      <td>Sales</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Bill Review Manager</td>\n",
       "      <td>US, FL, Fort Worth</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SpotSource Solutions LLC is a Global Human Cap...</td>\n",
       "      <td>JOB TITLE: Itemization Review ManagerLOCATION:...</td>\n",
       "      <td>QUALIFICATIONS:RN license in the State of Texa...</td>\n",
       "      <td>Full Benefits Offered</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Hospital &amp; Health Care</td>\n",
       "      <td>Health Care Provider</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   job_id                                      title            location  \\\n",
       "0       1                           Marketing Intern    US, NY, New York   \n",
       "1       2  Customer Service - Cloud Video Production      NZ, , Auckland   \n",
       "2       3    Commissioning Machinery Assistant (CMA)       US, IA, Wever   \n",
       "3       4          Account Executive - Washington DC  US, DC, Washington   \n",
       "4       5                        Bill Review Manager  US, FL, Fort Worth   \n",
       "\n",
       "  department salary_range                                    company_profile  \\\n",
       "0  Marketing               We're Food52, and we've created a groundbreaki...   \n",
       "1    Success               90 Seconds, the worlds Cloud Video Production ...   \n",
       "2                          Valor Services provides Workforce Solutions th...   \n",
       "3      Sales               Our passion for improving quality of life thro...   \n",
       "4                          SpotSource Solutions LLC is a Global Human Cap...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Food52, a fast-growing, James Beard Award-winn...   \n",
       "1  Organised - Focused - Vibrant - Awesome!Do you...   \n",
       "2  Our client, located in Houston, is actively se...   \n",
       "3  THE COMPANY: ESRI – Environmental Systems Rese...   \n",
       "4  JOB TITLE: Itemization Review ManagerLOCATION:...   \n",
       "\n",
       "                                        requirements  \\\n",
       "0  Experience with content management systems a m...   \n",
       "1  What we expect from you:Your key responsibilit...   \n",
       "2  Implement pre-commissioning and commissioning ...   \n",
       "3  EDUCATION: Bachelor’s or Master’s in GIS, busi...   \n",
       "4  QUALIFICATIONS:RN license in the State of Texa...   \n",
       "\n",
       "                                            benefits  telecommuting  \\\n",
       "0                                                                 0   \n",
       "1  What you will get from usThrough being part of...              0   \n",
       "2                                                                 0   \n",
       "3  Our culture is anything but corporate—we have ...              0   \n",
       "4                              Full Benefits Offered              0   \n",
       "\n",
       "   has_company_logo  has_questions employment_type required_experience  \\\n",
       "0                 1              0           Other          Internship   \n",
       "1                 1              0       Full-time      Not Applicable   \n",
       "2                 1              0                                       \n",
       "3                 1              0       Full-time    Mid-Senior level   \n",
       "4                 1              1       Full-time    Mid-Senior level   \n",
       "\n",
       "  required_education                   industry              function  \\\n",
       "0                                                           Marketing   \n",
       "1                     Marketing and Advertising      Customer Service   \n",
       "2                                                                       \n",
       "3  Bachelor's Degree          Computer Software                 Sales   \n",
       "4  Bachelor's Degree     Hospital & Health Care  Health Care Provider   \n",
       "\n",
       "   fraudulent  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"fake_job_postings.csv\")\n",
    "df = df.fillna(\"\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74bf593a-2873-448c-b5bf-6918b00e0a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Marketing and Advertising': 828,\n",
       " 'Computer Software': 1376,\n",
       " 'Hospital & Health Care': 497,\n",
       " 'Online Media': 101,\n",
       " 'Information Technology and Services': 1734,\n",
       " 'Financial Services': 779,\n",
       " 'Management Consulting': 130,\n",
       " 'Events Services': 50,\n",
       " 'Internet': 1062,\n",
       " 'Facilities Services': 94,\n",
       " 'Consumer Electronics': 62,\n",
       " 'Telecommunications': 342,\n",
       " 'Consumer Services': 358,\n",
       " 'Construction': 158,\n",
       " 'Oil & Energy': 287,\n",
       " 'Education Management': 822,\n",
       " 'Building Materials': 78,\n",
       " 'Banking': 84,\n",
       " 'Food & Beverages': 72,\n",
       " 'Food Production': 44,\n",
       " 'Health, Wellness and Fitness': 127,\n",
       " 'Insurance': 123,\n",
       " 'E-Learning': 139,\n",
       " 'Cosmetics': 65,\n",
       " 'Staffing and Recruiting': 127,\n",
       " 'Venture Capital & Private Equity': 29,\n",
       " 'Leisure, Travel & Tourism': 76,\n",
       " 'Human Resources': 108,\n",
       " 'Pharmaceuticals': 42,\n",
       " 'Farming': 24,\n",
       " 'Legal Services': 97,\n",
       " 'Luxury Goods & Jewelry': 4,\n",
       " 'Machinery': 11,\n",
       " 'Real Estate': 175,\n",
       " 'Mechanical or Industrial Engineering': 37,\n",
       " 'Public Relations and Communications': 58,\n",
       " 'Consumer Goods': 63,\n",
       " 'Medical Practice': 60,\n",
       " 'Electrical/Electronic Manufacturing': 73,\n",
       " 'Hospitality': 88,\n",
       " 'Music': 10,\n",
       " 'Market Research': 54,\n",
       " 'Automotive': 120,\n",
       " 'Philanthropy': 4,\n",
       " 'Utilities': 33,\n",
       " 'Primary/Secondary Education': 6,\n",
       " 'Logistics and Supply Chain': 112,\n",
       " 'Design': 129,\n",
       " 'Gambling & Casinos': 42,\n",
       " 'Accounting': 159,\n",
       " 'Environmental Services': 49,\n",
       " 'Mental Health Care': 23,\n",
       " 'Investment Management': 6,\n",
       " 'Apparel & Fashion': 97,\n",
       " 'Media Production': 48,\n",
       " 'Publishing': 39,\n",
       " 'Medical Devices': 19,\n",
       " 'Information Services': 28,\n",
       " 'Retail': 223,\n",
       " 'Sports': 23,\n",
       " 'Computer Games': 86,\n",
       " 'Chemicals': 22,\n",
       " 'Aviation & Aerospace': 24,\n",
       " 'Business Supplies and Equipment': 18,\n",
       " 'Program Development': 9,\n",
       " 'Computer Networking': 44,\n",
       " 'Biotechnology': 38,\n",
       " 'Civic & Social Organization': 55,\n",
       " 'Religious Institutions': 6,\n",
       " 'Warehousing': 51,\n",
       " 'Airlines/Aviation': 63,\n",
       " 'Writing and Editing': 19,\n",
       " 'Restaurants': 52,\n",
       " 'Outsourcing/Offshoring': 19,\n",
       " 'Transportation/Trucking/Railroad': 53,\n",
       " 'Wireless': 4,\n",
       " 'Investment Banking': 4,\n",
       " 'Nonprofit Organization Management': 76,\n",
       " 'Libraries': 2,\n",
       " 'Computer Hardware': 35,\n",
       " 'Broadcast Media': 50,\n",
       " 'Printing': 30,\n",
       " 'Graphic Design': 32,\n",
       " 'Entertainment': 74,\n",
       " 'Wholesale': 11,\n",
       " 'Research': 29,\n",
       " 'Animation': 5,\n",
       " 'Government Administration': 22,\n",
       " 'Capital Markets': 5,\n",
       " 'Computer & Network Security': 49,\n",
       " 'Semiconductors': 11,\n",
       " 'Security and Investigations': 30,\n",
       " 'Architecture & Planning': 10,\n",
       " 'Maritime': 3,\n",
       " 'Fund-Raising': 16,\n",
       " 'Higher Education': 11,\n",
       " 'Renewables & Environment': 9,\n",
       " 'Motion Pictures and Film': 6,\n",
       " 'Law Practice': 19,\n",
       " 'Government Relations': 11,\n",
       " 'Packaging and Containers': 5,\n",
       " 'Sporting Goods': 1,\n",
       " 'Mining & Metals': 3,\n",
       " 'Import and Export': 5,\n",
       " 'International Trade and Development': 8,\n",
       " 'Professional Training & Coaching': 14,\n",
       " 'Textiles': 2,\n",
       " 'Commercial Real Estate': 4,\n",
       " 'Law Enforcement': 10,\n",
       " 'Package/Freight Delivery': 5,\n",
       " 'Translation and Localization': 10,\n",
       " 'Photography': 7,\n",
       " 'Industrial Automation': 7,\n",
       " 'Wine and Spirits': 1,\n",
       " 'Public Safety': 7,\n",
       " 'Civil Engineering': 9,\n",
       " 'Military': 2,\n",
       " 'Defense & Space': 9,\n",
       " 'Veterinary': 8,\n",
       " 'Executive Office': 8,\n",
       " 'Performing Arts': 3,\n",
       " 'Individual & Family Services': 9,\n",
       " 'Public Policy': 3,\n",
       " 'Nanotechnology': 2,\n",
       " 'Museums and Institutions': 1,\n",
       " 'Fishery': 4,\n",
       " 'Plastics': 3,\n",
       " 'Furniture': 3,\n",
       " 'Shipbuilding': 1,\n",
       " 'Alternative Dispute Resolution': 1,\n",
       " 'Ranching': 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmap = {}\n",
    "for l in df['industry']:\n",
    "    if l == '': continue\n",
    "    if l in mmap:\n",
    "        mmap[l] += 1\n",
    "    else:\n",
    "        mmap[l] = 1\n",
    "mmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fb76238-ee73-4b4e-a755-96d7632d76f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Marketing': 830,\n",
       " 'Customer Service': 1229,\n",
       " 'Sales': 1468,\n",
       " 'Health Care Provider': 338,\n",
       " 'Management': 317,\n",
       " 'Information Technology': 1749,\n",
       " 'Other': 325,\n",
       " 'Engineering': 1348,\n",
       " 'Administrative': 630,\n",
       " 'Design': 340,\n",
       " 'Production': 116,\n",
       " 'Education': 325,\n",
       " 'Supply Chain': 36,\n",
       " 'Business Development': 228,\n",
       " 'Product Management': 114,\n",
       " 'Financial Analyst': 33,\n",
       " 'Consulting': 144,\n",
       " 'Human Resources': 205,\n",
       " 'Project Management': 183,\n",
       " 'Manufacturing': 74,\n",
       " 'Public Relations': 76,\n",
       " 'Strategy/Planning': 46,\n",
       " 'Advertising': 90,\n",
       " 'Finance': 172,\n",
       " 'General Business': 68,\n",
       " 'Research': 50,\n",
       " 'Accounting/Auditing': 212,\n",
       " 'Art/Creative': 132,\n",
       " 'Quality Assurance': 111,\n",
       " 'Data Analyst': 82,\n",
       " 'Business Analyst': 84,\n",
       " 'Writing/Editing': 132,\n",
       " 'Distribution': 24,\n",
       " 'Science': 14,\n",
       " 'Training': 38,\n",
       " 'Purchasing': 15,\n",
       " 'Legal': 47}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmap = {}\n",
    "for l in df['function']:\n",
    "    if l == '': continue\n",
    "    if l in mmap:\n",
    "        mmap[l] += 1\n",
    "    else:\n",
    "        mmap[l] = 1\n",
    "mmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfa1ff78-9ef9-4ab0-bc86-12009fb2f6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"Bachelor's Degree\": 5145,\n",
       " \"Master's Degree\": 416,\n",
       " 'High School or equivalent': 2080,\n",
       " 'Unspecified': 1397,\n",
       " 'Some College Coursework Completed': 102,\n",
       " 'Vocational': 49,\n",
       " 'Certification': 170,\n",
       " 'Associate Degree': 274,\n",
       " 'Professional': 74,\n",
       " 'Doctorate': 26,\n",
       " 'Some High School Coursework': 27,\n",
       " 'Vocational - Degree': 6,\n",
       " 'Vocational - HS Diploma': 9}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edu_map = {}\n",
    "for l in df['required_education']:\n",
    "    if l == '': continue\n",
    "    if l in edu_map:\n",
    "        edu_map[l] += 1\n",
    "    else:\n",
    "        edu_map[l] = 1\n",
    "edu_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f51cc99-c54a-4ccc-9bf6-ea9244d48e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'US': 10656,\n",
       " 'NZ': 333,\n",
       " 'DE': 383,\n",
       " 'GB': 2384,\n",
       " 'AU': 214,\n",
       " 'SG': 80,\n",
       " 'IL': 72,\n",
       " 'AE': 54,\n",
       " 'CA': 457,\n",
       " 'IN': 276,\n",
       " 'EG': 52,\n",
       " 'PL': 76,\n",
       " 'GR': 940,\n",
       " '': 346,\n",
       " 'PK': 27,\n",
       " 'BE': 117,\n",
       " 'BR': 36,\n",
       " 'SA': 15,\n",
       " 'DK': 42,\n",
       " 'RU': 20,\n",
       " 'ZA': 40,\n",
       " 'CY': 11,\n",
       " 'HK': 77,\n",
       " 'TR': 17,\n",
       " 'IE': 114,\n",
       " 'LT': 23,\n",
       " 'JP': 20,\n",
       " 'NL': 127,\n",
       " 'AT': 14,\n",
       " 'KR': 10,\n",
       " 'FR': 70,\n",
       " 'EE': 72,\n",
       " 'TH': 10,\n",
       " 'PA': 9,\n",
       " 'KE': 7,\n",
       " 'MU': 14,\n",
       " 'MX': 18,\n",
       " 'RO': 46,\n",
       " 'MY': 21,\n",
       " 'FI': 29,\n",
       " 'CN': 15,\n",
       " 'ES': 66,\n",
       " 'SE': 49,\n",
       " 'CL': 2,\n",
       " 'UA': 13,\n",
       " 'QA': 21,\n",
       " 'IT': 31,\n",
       " 'LV': 6,\n",
       " 'IQ': 10,\n",
       " 'BG': 17,\n",
       " 'PH': 132,\n",
       " 'CZ': 6,\n",
       " 'VI': 3,\n",
       " 'MT': 13,\n",
       " 'HU': 14,\n",
       " 'BD': 2,\n",
       " 'KW': 2,\n",
       " 'LU': 9,\n",
       " 'NG': 10,\n",
       " 'RS': 7,\n",
       " 'BY': 9,\n",
       " 'VN': 4,\n",
       " 'ID': 13,\n",
       " 'ZM': 2,\n",
       " 'NO': 8,\n",
       " 'BH': 9,\n",
       " 'UG': 1,\n",
       " 'CH': 15,\n",
       " 'TT': 4,\n",
       " 'SD': 1,\n",
       " 'SK': 2,\n",
       " 'AR': 9,\n",
       " 'TW': 4,\n",
       " 'PT': 18,\n",
       " 'PE': 1,\n",
       " 'CO': 1,\n",
       " 'IS': 2,\n",
       " 'SI': 1,\n",
       " 'MA': 1,\n",
       " 'AM': 2,\n",
       " 'TN': 2,\n",
       " 'GH': 1,\n",
       " 'AL': 1,\n",
       " 'HR': 1,\n",
       " 'CM': 1,\n",
       " 'SV': 1,\n",
       " 'NI': 4,\n",
       " 'LK': 2,\n",
       " 'JM': 1,\n",
       " 'KZ': 1,\n",
       " 'KH': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locNum = {}\n",
    "for l in df['location']:\n",
    "    frags = l.split(',')\n",
    "    country = frags[0]\n",
    "    if country in locNum:\n",
    "        locNum[country] += 1\n",
    "    else:\n",
    "        locNum[country] = 1\n",
    "locNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3535aee8-5e2d-4cbc-b246-5dc513b93e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000-28000 : 1 100000-120000 : 1 120000-150000 : 1 50000-65000 : 1 40000-50000 : 1 60-80 : 1 65000-70000 : 1 75-115 : 1 75000-110000 : 1 17000-20000 : 1 16000-28000 : 1 95000-115000 : 1 15000-18000 : 1 50000-70000 : 1 45000-60000 : 1 30000-40000 : 1 70000-90000 : 1 10000-14000 : 1 50-110 : 1 28000-45000 : 1 0-34300 : 1 35000-40000 : 1 9-Dec : 1 44000-57000 : 1 18500-28000 : 1 55000-75000 : 1 30000-35000 : 1 0-0 : 1 20000-40000 : 1 360000-600000 : 1 50000-80000 : 1 80000-100000 : 1 52000-78000 : 1 15750-15750 : 1 40000-65000 : 1 45000-50000 : 1 30000-37000 : 1 45000-67000 : 1 35000-100000 : 1 180000-216000 : 1 45000-65000 : 1 28000-32000 : 1 0-1000 : 1 36000-40000 : 1 80000-110000 : 1 35000-73000 : 1 19000-19000 : 1 60000-120000 : 1 120000-15000000 : 1 42000-55000 : 1 90000-120000 : 1 100000-150000 : 1 28000-38000 : 1 1600-1700 : 1 50000-60000 : 1 30000-70000 : 1 32000-40000 : 1 50-100 : 1 9000-17000 : 1 23040-28800 : 1 105-110 : 1 13000-16000 : 1 100000-180000 : 1 45000-55000 : 1 9000-12000 : 1 50000-90000 : 1 25000-42000 : 1 40000-60000 : 1 600000-750000 : 1 120000-170000 : 1 45000-90000 : 1 25000-30000 : 1 65000-75000 : 1 18000-19000 : 1 100000-130000 : 1 18000-20000 : 1 22000-30000 : 1 5000-6000 : 1 36000-52000 : 1 11000-11000 : 1 110000-150000 : 1 50000-150000 : 1 100000-600000 : 1 80000-120000 : 1 10800-10800 : 1 50000-72000 : 1 35000-150000 : 1 60000-100000 : 1 70000-125000 : 1 37000-37000 : 1 0-130000 : 1 75000-120000 : 1 20000-20000 : 1 45000-85000 : 1 25000-35000 : 1 120000-165000 : 1 23000-32000 : 1 18000-21000 : 1 100000-300000 : 1 65000-80000 : 1 55000-60000 : 1 40000-85000 : 1 30000-60000 : 1 40000-70000 : 1 75000-85000 : 1 320000-350000 : 1 110000-140000 : 1 20000-35000 : 1 20000-26000 : 1 70000-120000 : 1 85000-125000 : 1 9600-18000 : 1 28000-40000 : 1 90-120 : 1 4001-6000 : 1 18000-30000 : 1 95000-125000 : 1 30000-45000 : 1 60000-75000 : 1 30000-1000000 : 1 40000-55000 : 1 55000-65000 : 1 35000-45000 : 1 20000-30000 : 1 90000-100000 : 1 180000-240000 : 1 75-100 : 1 1161-1161 : 1 36000-48000 : 1 30000-50000 : 1 60000-80000 : 1 35-45 : 1 15000-20000 : 1 21000-25000 : 1 16000-18500 : 1 16000-24000 : 1 110000-130000 : 1 40000-45000 : 1 28000-35000 : 1 80000-105000 : 1 36000-63000 : 1 60000-90000 : 1 124000-375000 : 1 50-53 : 1 90000-110000 : 1 50000-55000 : 1 33000-36000 : 1 35000-65000 : 1 26000-30000 : 1 40000-80000 : 1 9600-57600 : 1 75000-125000 : 1 24000-26000 : 1 36000-50000 : 1 85-140 : 1 7000-9000 : 1 75000-80000 : 1 0-90000 : 1 4500-4500 : 1 25000-50000 : 1 70-100 : 1 70000-85000 : 1 2500-3500 : 1 130000-160000 : 1 15000-30000 : 1 65000-85000 : 1 21120-30000 : 1 48000-57600 : 1 20000-50000 : 1 84000-102000 : 1 500000-650000 : 1 24000-32000 : 1 28000-42000 : 1 80000-90000 : 1 13-20 : 1 1000-2000 : 1 35000-120000 : 1 1000-20000 : 1 18000-22000 : 1 50000-120000 : 1 20000-25000 : 1 75000-150000 : 1 0-30000 : 1 15000-17000 : 1 14000-18000 : 1 55386-66731 : 1 115000-125000 : 1 70000-80000 : 1 21-63000 : 1 16500-17500 : 1 18000-25000 : 1 14000-16000 : 1 35000-50000 : 1 3-Apr : 1 10000-15000 : 1 15500-50000 : 1 120000-240000 : 1 60000-70000 : 1 20000-38000 : 1 23000-28000 : 1 52000-57000 : 1 4-Apr : 1 44624-53764 : 1 12000-12000 : 1 15600-15600 : 1 1600-1600 : 1 25000-36000 : 1 8000-10000 : 1 20000-23000 : 1 100-200 : 1 0-50000 : 1 1100-1200 : 1 100000-110000 : 1 45000-45000 : 1 96000-100000 : 1 40000-40000 : 1 33000-34000 : 1 18000-44000 : 1 16000-20000 : 1 1050-1100 : 1 50000-100000 : 1 21000-21000 : 1 9600-10500 : 1 400000-650000 : 1 Oct-15 : 1 800000-2000000 : 1 335000-400000 : 1 1000-1000 : 1 19000-24000 : 1 45000-70000 : 1 960000-1200000 : 1 55-65 : 1 23000-96000 : 1 110000-120000 : 1 50-70 : 1 480000-600000 : 1 1000-5000 : 1 80000-175000 : 1 35000-35000 : 1 75000-100000 : 1 24900-31200 : 1 42000-48000 : 1 27000-28000 : 1 18000-23000 : 1 10716-16074 : 1 0-9360000 : 1 0-268 : 1 20000-22000 : 1 37400-37400 : 1 49000-58000 : 1 80000-80000 : 1 25000-40000 : 1 15000-16000 : 1 25000-75000 : 1 100000-200000 : 1 39000-100000 : 1 140000-150000 : 1 80000-119000 : 1 80000-200000 : 1 30000-38000 : 1 20-3075 : 1 40000-120000 : 1 25000-27000 : 1 25000-100000 : 1 120000-160000 : 1 16500-18500 : 1 20000-60000 : 1 36000-42000 : 1 17000-19000 : 1 40000-140000 : 1 800000000-1200000000 : 1 35000-55000 : 1 0-45000 : 1 40000-100000 : 1 45-75 : 1 42000-62000 : 1 23000-26000 : 1 70000-300000 : 1 77000-97000 : 1 16000-18000 : 1 80000-130000 : 1 18-22 : 1 30000-37500 : 1 50-60 : 1 32500-37500 : 1 140000-160000 : 1 19800-20800 : 1 13000-14000 : 1 80000-85000 : 1 0-1 : 1 200000-600000 : 1 12500-15000 : 1 300000-330000 : 1 39000-42000 : 1 23000-24000 : 1 70000-150000 : 1 18720-21840 : 1 29000-33000 : 1 20000-24000 : 1 130000-150000 : 1 400000-600000 : 1 17000-22000 : 1 67000-70000 : 1 12000-24000 : 1 19000-36000 : 1 540000-720000 : 1 80000-84000 : 1 180000-600000 : 1 14560-17680 : 1 450-500 : 1 9600-14400 : 1 32000-34000 : 1 20-25 : 1 1000-6000 : 1 22000-25000 : 1 30160-30160 : 1 22000-26000 : 1 110000-125000 : 1 66000-84000 : 1 30000-450000 : 1 14000-17000 : 1 18000-24000 : 1 41000-45000 : 1 12000-17000 : 1 16000-19200 : 1 60-70 : 1 35000-60000 : 1 13-15 : 1 30000-30000 : 1 80000-140000 : 1 55000-70000 : 1 8-Sep : 1 65000-120000 : 1 0-25000 : 1 0-15000 : 1 36000-65000 : 1 17000-32000 : 1 0-24000 : 1 0-1200000 : 1 55000-100000 : 1 200000-500000 : 1 10000-16000 : 1 14000-40000 : 1 200-230 : 1 3000-100000 : 1 12000-45000 : 1 721000-780000 : 1 0-92000 : 1 70-90 : 1 22000-22000 : 1 135-165 : 1 2000-5000 : 1 39000-41000 : 1 30-50 : 1 30000-36000 : 1 90000-125000 : 1 100000-240000 : 1 2500-5000 : 1 110-140 : 1 2000-6000 : 1 17000-21000 : 1 95000-150000 : 1 90000-130000 : 1 70-120 : 1 32000-36000 : 1 55000-80000 : 1 1000-3000 : 1 350000-500000 : 1 3000000-4000000 : 1 25000-28000 : 1 70000-130000 : 1 100000-160000 : 1 3000-6000 : 1 30000-100000 : 1 130000-145000 : 1 20000-100000 : 1 41600-62400 : 1 6266624-8582080 : 1 2000-2000 : 1 20000-500000 : 1 95000-110000 : 1 19000-26000 : 1 120000-130000 : 1 140000-200000 : 1 42000-80000 : 1 34000-50000 : 1 40000-75000 : 1 22000-60000 : 1 24000-28000 : 1 0-100000 : 1 800000-1200000 : 1 60-150 : 1 15000-75000 : 1 10000-30000 : 1 15000-25000 : 1 0-2000 : 1 33000-53000 : 1 28000-28000 : 1 50000-75000 : 1 5000-10000 : 1 40000 : 1 17000-24000 : 1 20000-36000 : 1 29120-37440 : 1 30000-48000 : 1 35-100 : 1 45000-96000 : 1 1000-1500 : 1 12500-14000 : 1 40000-41000 : 1 34000-35000 : 1 7200-1380000 : 1 26000-29000 : 1 180000-200000 : 1 0-20000 : 1 20800-22880 : 1 22000-28000 : 1 14000-14000 : 1 2000-40000 : 1 23000-25000 : 1 28000-30000 : 1 12000-17500 : 1 34000-38000 : 1 32-35 : 1 750-750 : 1 35-40 : 1 600000-800000 : 1 20800-22800 : 1 27-30 : 1 250000-500000 : 1 27000-32000 : 1 85-95 : 1 50000-85000 : 1 500000-800000 : 1 110-120 : 1 20-22 : 1 27500-36000 : 1 300000-325000 : 1 80-100 : 1 60-75 : 1 15-25 : 1 240000-500000 : 1 4000-5000 : 1 0-65000 : 1 17000-30000 : 1 0-43500 : 1 25-1000 : 1 21600-31200 : 1 23000-30000 : 1 45-48 : 1 36000-200000 : 1 26000-52000 : 1 900-900 : 1 85000-95000 : 1 160000-180000 : 1 50000-300000 : 1 80000-95000 : 1 2800-3500 : 1 100-150 : 1 100-120 : 1 26000-32000 : 1 25000-45000 : 1 32000-52000 : 1 130000-180000 : 1 2000-4000 : 1 70000-110000 : 1 45000-75000 : 1 20000-27000 : 1 2000000-15000000 : 1 65000-72000 : 1 6000000-7000000 : 1 18000-18000 : 1 55000-85000 : 1 120000-120000 : 1 60000-65000 : 1 200000-250000 : 1 37500-42500 : 1 70000-100000 : 1 29000-32000 : 1 45-65 : 1 0-35000 : 1 0-150000 : 1 14000-22400 : 1 150000-160000 : 1 200-250 : 1 0-95000 : 1 15000-200000 : 1 65000-115000 : 1 50-90 : 1 18500-25000 : 1 75000-90000 : 1 92000-141000 : 1 35-60 : 1 1000-26000 : 1 76800-96000 : 1 46000-55000 : 1 32000-45000 : 1 27000-34000 : 1 85000-110000 : 1 12000-19000 : 1 30000-34000 : 1 196000-230000 : 1 42000-58000 : 1 150000-16500000 : 1 60000-73000 : 1 240000-240000 : 1 17-20 : 1 32000-46000 : 1 100000-250000 : 1 24000-27600 : 1 25000-25000 : 1 8000-13000 : 1 22000-24000 : 1 85000-120000 : 1 40-50 : 1 35000-95000 : 1 35000-75000 : 1 318278-400000 : 1 120000-140000 : 1 600000-1200000 : 1 100000-117000 : 1 45000-95000 : 1 55-105 : 1 33000-100000 : 1 14400-24000 : 1 24-25 : 1 125-175 : 1 250000-300000 : 1 175-225 : 1 14000-15000 : 1 1000-10000 : 1 120-160 : 1 10000-100000 : 1 25-28 : 1 65000-100000 : 1 48000-60000 : 1 600000-1000000 : 1 33280-37440 : 1 5000-7000 : 1 107000-115000 : 1 80000-89000 : 1 0-16000 : 1 14-15 : 1 45000-80000 : 1 18720-19760 : 1 35000-36000 : 1 190000-220000 : 1 35000-70000 : 1 37000-40000 : 1 1500000-2500000 : 1 65000-110000 : 1 700000-1200000 : 1 23000-27000 : 1 72000-144000 : 1 5500-5500 : 1 10000-20000 : 1 420000-540000 : 1 99000-99999 : 1 0-180000 : 1 0-120000 : 1 25000-31000 : 1 55000-68000 : 1 4-Jun : 1 1300000-1800000 : 1 40000-54000 : 1 10000-120000 : 1 100000-125000 : 1 42000-54000 : 1 220000-225000 : 1 45000-58000 : 1 0-110406 : 1 3000-7000 : 1 17-19 : 1 24000-29000 : 1 26000-31000 : 1 250000-550000 : 1 12000-15000 : 1 168000-216000 : 1 40-80 : 1 125000-135000 : 1 40000-46000 : 1 10000-10000 : 1 200000-300000 : 1 90-110 : 1 850-1000 : 1 33000-63000 : 1 9000-10000 : 1 40-100 : 1 900000-1200000 : 1 26000-28000 : 1 17000-35000 : 1 17500-17500 : 1 50000-50000 : 1 150000-200000 : 1 90-100 : 1 10-Oct : 1 Oct-20 : 1 13000-15000 : 1 24000-36000 : 1 100000-115000 : 1 105000-125000 : 1 65000-90000 : 1 10000-22000 : 1 Jun-18 : 1 1000-1100 : 1 3000-60000 : 1 120000-135000 : 1 38000-45000 : 1 18500-27000 : 1 30-40 : 1 71000-72000 : 1 30000-65000 : 1 90000-150000 : 1 200000-240000 : 1 900-1000 : 1 70000-160000 : 1 32000-37440 : 1 80-110 : 1 29000-40000 : 1 42000-46000 : 1 1000000-1400000 : 1 11-Nov : 1 1150-1150 : 1 55000-90000 : 1 10-Nov : 1 956-956 : 1 40000-47000 : 1 42000-42000 : 1 90000-95000 : 1 120000-125000 : 1 125000-150000 : 1 21000-35000 : 1 14000-25000 : 1 240000-300000 : 1 300000-420000 : 1 11-Dec : 1 14000-30000 : 1 150-175 : 1 2-Apr : 1 90000-140000 : 1 25000-32000 : 1 42000-60000 : 1 15000-19000 : 1 0-48000 : 1 175000-250000 : 1 60000-96000 : 1 22000-40000 : 1 150000-250000 : 1 80000-150000 : 1 25000-65000 : 1 60000-72000 : 1 550000-720000 : 1 9240-13200 : 1 41600-52000 : 1 120000-180000 : 1 50000-58000 : 1 55000-79000 : 1 10000-18000 : 1 30000-80000 : 1 300000-400000 : 1 750000-1200000 : 1 41000-50000 : 1 36000-54000 : 1 200000-700000 : 1 10000-12000 : 1 24000-30000 : 1 100000-170000 : 1 40000-90000 : 1 1200-3000 : 1 300000-600000 : 1 77000-87000 : 1 78000-80000 : 1 0-60000 : 1 115000-130000 : 1 500000000-800000000 : 1 85000-90000 : 1 2500-2500 : 1 44000-102000 : 1 28000-34000 : 1 70000-105000 : 1 46000-62000 : 1 2000000-2263000 : 1 6000-20000 : 1 15500-17500 : 1 0-32000 : 1 96000-240000 : 1 15400-19600 : 1 2000-2500 : 1 45000-63000 : 1 31181-37566 : 1 16000-16000 : 1 80000-250000 : 1 32000-50000 : 1 85000-100000 : 1 45000-120000 : 1 27000-34280 : 1 16000-19000 : 1 90000-115000 : 1 1300-1500 : 1 600000-840000 : 1 19500-24000 : 1 26400-36000 : 1 43000-69000 : 1 8000-14000 : 1 60-65 : 1 24000-35000 : 1 65-75 : 1 70-150 : 1 60-90 : 1 1200-1400 : 1 60-85 : 1 2-Jun : 1 38000-52000 : 1 65-100 : 1 528000-636000 : 1 90-140000 : 1 115-120 : 1 45-70 : 1 962-962 : 1 2500-2800 : 1 30000-31000 : 1 80-120 : 1 78000-115000 : 1 30000-32000 : 1 70000-126000 : 1 11000-25000 : 1 72000-108000 : 1 48000-55000 : 1 35000-48000 : 1 1000000-1500000 : 1 50-65 : 1 38000-65000 : 1 400000-500000 : 1 60000-150000 : 1 41600-50000 : 1 104000-120000 : 1 63000-63000 : 1 37000-41600 : 1 52000-100000 : 1 120000-300000 : 1 130000-170000 : 1 91000-150000 : 1 60000-95000 : 1 7500-8000 : 1 36000-60000 : 1 12500-12500 : 1 65000-77000 : 1 33000-39000 : 1 300000-500000 : 1 1920-2000 : 1 192000-288000 : 1 32000-42000 : 1 32000-37000 : 1 45000-72000 : 1 96000-120000 : 1 70000-95000 : 1 0-70000 : 1 1000-1400 : 1 7-12000 : 1 10000-25000 : 1 115000-160000 : 1 60000-160000 : 1 1000-4000 : 1 30000-49000 : 1 18000-26000 : 1 30000-42000 : 1 0-115 : 1 14436-28000 : 1 30000-40700 : 1 34000-44000 : 1 12000-18000 : 1 110000-135000 : 1 40-60 : 1 16000-25000 : 1 25-35 : 1 38000-75000 : 1 8000-20000 : 1 16000-22000 : 1 6000-15000 : 1 24960-27040 : 1 30000-39000 : 1 55000-755000 : 1 85000-105000 : 1 48000-58000 : 1 100000-400000 : 1 96000-144000 : 1 144000-192000 : 1 45-85 : 1 19200-33600 : 1 60000-85000 : 1 120000-264000 : 1 27000-30000 : 1 18720-18720 : 1 13000-18000 : 1 38000-48000 : 1 1600-19000 : 1 60000-130000 : 1 120000-168000 : 1 75000-95000 : 1 3000-4000 : 1 0-38000 : 1 0-12500 : 1 175000-275000 : 1 32000-35000 : 1 34000-45000 : 1 21000-36000 : 1 35000-42000 : 1 200000-280000 : 1 22-28 : 1 30000-33000 : 1 240000-600000 : 1 65000-125000 : 1 95000-105000 : 1 300000-450000 : 1 90-150 : 1 30-35 : 1 40-55 : 1 45000-175000 : 1 143520-197600 : 1 85000-150000 : 1 145600-187200 : 1 166400-260000 : 1 55-125 : 1 33000-37000 : 1 45-80 : 1 200000-400000 : 1 93600-122720 : 1 65000-140000 : 1 400000-450000 : 1 8000-9000 : 1 208000-270400 : 1 360000-400000 : 1 83200-114400 : 1 93600-114400 : 1 156000-187200 : 1 70000-200000 : 1 15-17 : 1 20000-21000 : 1 55-72 : 1 50-95 : 1 45-67 : 1 55-67 : 1 35000-38000 : 1 48-60 : 1 27000-29000 : 1 45-55 : 1 20800-20800 : 1 240000-480000 : 1 6000-10000 : 1 1050-1050 : 1 14000-36000 : 1 14500-19000 : 1 20000-260000 : 1 55000-69000 : 1 360000-500000 : 1 50000-95000 : 1 16-20 : 1 140-160 : 1 15500-16500 : 1 10000-250000 : 1 2000-3000 : 1 4500-5000 : 1 26000-50000 : 1 25-30 : 1 Dec-25 : 1 1517-1517 : 1 1234-12345 : 1 34000-42000 : 1 15-19 : 1 21-31 : 1 48000-65000 : 1 53000-67000 : 1 22-61000 : 1 3700-3800 : 1 "
     ]
    }
   ],
   "source": [
    "salary_map = {}\n",
    "for l in df['salary_range']:\n",
    "    if l == '': continue\n",
    "    if l in locNum:\n",
    "        salary_map[l] += 1\n",
    "    else:\n",
    "        salary_map[l] = 1\n",
    "for key in salary_map:\n",
    "    print(key,':',salary_map[key],end = ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0324b58-600a-43e3-b455-2e5a8208825d",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "Because we are operating the plane in a algebra space, we only want numerical values. For all the 17 features, I would perform data pre processing as follows:\n",
    "\n",
    " job id: maybe related to job created time? treat as integer\n",
    " \n",
    " title: split into several features, like intern, account, etc. As first input, could gather into text vector.\n",
    " \n",
    " location: split into US and non US group because lack of data in some minor countries, like: is_US(1 for in US 0 for not) \n",
    " \n",
    " department, missing too much data, maybe will collect as text\n",
    " \n",
    " salary range, missing data, may use as 3, has_salary_range, salary_lower, salary_higher, treat as int.\n",
    " \n",
    " company profile: vectorize, gather as text vector.\n",
    " \n",
    " desc, req, vectorize, split, gather as text vector.\n",
    " \n",
    " benefits, missing data, may use and vectorize. If there are, gather as text vector.\n",
    " \n",
    " telecommuting\thas_company_logo\thas_questions, use as it is\n",
    " \n",
    " mployment_type\trequired_experience\trequired_education\tindustry\tfunction\tsplit and use, maybe one more feature for having NaN or not\n",
    " \n",
    " fraudulent: target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "139fb379-f804-47c6-a404-191d85cc8d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanDf = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f404d089-0f9e-43e7-958c-da21bf0e507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanDf['telecommuting'] = df['telecommuting']\n",
    "CleanDf['has_company_logo'] = df['has_company_logo']\n",
    "CleanDf['has_questions'] = df['has_questions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d0e8b47-7662-44dd-b457-620309c72ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_map = {}\n",
    "for l in df['required_education']:\n",
    "    if l == '': continue\n",
    "    if l in edu_map:\n",
    "        edu_map[l] += 1\n",
    "    else:\n",
    "        edu_map[l] = 1\n",
    "add_map = {}\n",
    "add_map['has_edu_require'] = []\n",
    "for key in edu_map:\n",
    "    add_map[key] = []\n",
    "for l in df['required_education']:\n",
    "    if l == '':\n",
    "        add_map['has_edu_require'].append(0)\n",
    "        for key in edu_map:\n",
    "            add_map[key].append(0)\n",
    "    else:\n",
    "        add_map['has_edu_require'].append(1)\n",
    "        for key in edu_map:\n",
    "            if key == l: add_map[key].append(1)\n",
    "            else: add_map[key].append(0)\n",
    "for key in add_map:\n",
    "    CleanDf[key] = add_map[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffbd608b-cf81-47b6-8f59-0886967dda88",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_label = []\n",
    "lower_salary = []\n",
    "upper_salary = []\n",
    "for l in df['salary_range']:\n",
    "    try:\n",
    "        frags = l.split('-')\n",
    "        a = int(frags[0])\n",
    "        b = int(frags[1])\n",
    "        salary_label.append(1)\n",
    "        lower_salary.append(a)\n",
    "        upper_salary.append(b)\n",
    "    except:\n",
    "        salary_label.append(0)\n",
    "        lower_salary.append(0)\n",
    "        upper_salary.append(0)\n",
    "# print(salary_label,lower_salary,upper_salary)\n",
    "# min max normalization\n",
    "minimum = min(lower_salary)\n",
    "diff = max(lower_salary) - min(lower_salary)\n",
    "for i in range(len(lower_salary)): lower_salary[i] = (lower_salary[i] - minimum)/diff\n",
    "\n",
    "minimum = min(upper_salary)\n",
    "diff = max(upper_salary) - min(upper_salary)\n",
    "for i in range(len(upper_salary)): upper_salary[i] = (upper_salary[i] - minimum)/diff\n",
    "\n",
    "CleanDf['salary_label'] = salary_label\n",
    "CleanDf['lower_salary'] = lower_salary\n",
    "CleanDf['upper_salary'] = upper_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5583b504-b3f8-4be5-b8de-b32b47c36612",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_US = []\n",
    "for l in df['location']:\n",
    "    frags = l.split(',')\n",
    "    if frags[0] == 'US': is_US.append(1)\n",
    "    else: is_US.append(0)\n",
    "CleanDf['in_US'] = is_US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75161284-cb4a-4115-8894-f2ba0efb10e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IT / CS industry?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82837411-c9b0-41fa-abf9-44cd6a2105a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_map = {}\n",
    "for l in df['required_experience']:\n",
    "    if l == '': continue\n",
    "    if l in exp_map:\n",
    "        exp_map[l] += 1\n",
    "    else:\n",
    "        exp_map[l] = 1\n",
    "add_map = {}\n",
    "add_map['has_exp_require'] = []\n",
    "for key in exp_map:\n",
    "    add_map[key] = []\n",
    "for l in df['required_experience']:\n",
    "    if l == '':\n",
    "        add_map['has_exp_require'].append(0)\n",
    "        for key in exp_map:\n",
    "            add_map[key].append(0)\n",
    "    else:\n",
    "        add_map['has_exp_require'].append(1)\n",
    "        for key in exp_map:\n",
    "            if key == l: add_map[key].append(1)\n",
    "            else: add_map[key].append(0)\n",
    "for key in add_map:\n",
    "    CleanDf[key] = add_map[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4c2124b-1f02-4c17-ac2d-3ee67bf0724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_map = {}\n",
    "for l in df['function']:\n",
    "    if l == '': continue\n",
    "    if l in func_map:\n",
    "        func_map[l] += 1\n",
    "    else:\n",
    "        func_map[l] = 1\n",
    "add_map = {}\n",
    "add_map['has_function'] = []\n",
    "for key in func_map:\n",
    "    add_map[key] = []\n",
    "for l in df['function']:\n",
    "    if l == '':\n",
    "        add_map['has_function'].append(0)\n",
    "        for key in func_map:\n",
    "            add_map[key].append(0)\n",
    "    else:\n",
    "        add_map['has_function'].append(1)\n",
    "        for key in func_map:\n",
    "            if key == l: add_map[key].append(1)\n",
    "            else: add_map[key].append(0)\n",
    "for key in add_map:\n",
    "    CleanDf[key] = add_map[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f32085e7-d5dd-4980-8185-b8837087bca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanDf['fraudulent'] = df['fraudulent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31ee699d-21d5-4648-9469-b0b96d22f863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>telecommuting</th>\n",
       "      <th>has_company_logo</th>\n",
       "      <th>has_questions</th>\n",
       "      <th>has_edu_require</th>\n",
       "      <th>Bachelor's Degree</th>\n",
       "      <th>Master's Degree</th>\n",
       "      <th>High School or equivalent</th>\n",
       "      <th>Unspecified</th>\n",
       "      <th>Some College Coursework Completed</th>\n",
       "      <th>Vocational</th>\n",
       "      <th>...</th>\n",
       "      <th>Quality Assurance</th>\n",
       "      <th>Data Analyst</th>\n",
       "      <th>Business Analyst</th>\n",
       "      <th>Writing/Editing</th>\n",
       "      <th>Distribution</th>\n",
       "      <th>Science</th>\n",
       "      <th>Training</th>\n",
       "      <th>Purchasing</th>\n",
       "      <th>Legal</th>\n",
       "      <th>fraudulent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17875</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17876</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17877</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17878</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17879</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17880 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       telecommuting  has_company_logo  has_questions  has_edu_require  \\\n",
       "0                  0                 1              0                0   \n",
       "1                  0                 1              0                0   \n",
       "2                  0                 1              0                0   \n",
       "3                  0                 1              0                1   \n",
       "4                  0                 1              1                1   \n",
       "...              ...               ...            ...              ...   \n",
       "17875              0                 1              1                0   \n",
       "17876              0                 1              1                1   \n",
       "17877              0                 0              0                0   \n",
       "17878              0                 0              1                1   \n",
       "17879              0                 1              1                0   \n",
       "\n",
       "       Bachelor's Degree  Master's Degree  High School or equivalent  \\\n",
       "0                      0                0                          0   \n",
       "1                      0                0                          0   \n",
       "2                      0                0                          0   \n",
       "3                      1                0                          0   \n",
       "4                      1                0                          0   \n",
       "...                  ...              ...                        ...   \n",
       "17875                  0                0                          0   \n",
       "17876                  1                0                          0   \n",
       "17877                  0                0                          0   \n",
       "17878                  0                0                          0   \n",
       "17879                  0                0                          0   \n",
       "\n",
       "       Unspecified  Some College Coursework Completed  Vocational  ...  \\\n",
       "0                0                                  0           0  ...   \n",
       "1                0                                  0           0  ...   \n",
       "2                0                                  0           0  ...   \n",
       "3                0                                  0           0  ...   \n",
       "4                0                                  0           0  ...   \n",
       "...            ...                                ...         ...  ...   \n",
       "17875            0                                  0           0  ...   \n",
       "17876            0                                  0           0  ...   \n",
       "17877            0                                  0           0  ...   \n",
       "17878            0                                  0           0  ...   \n",
       "17879            0                                  0           0  ...   \n",
       "\n",
       "       Quality Assurance  Data Analyst  Business Analyst  Writing/Editing  \\\n",
       "0                      0             0                 0                0   \n",
       "1                      0             0                 0                0   \n",
       "2                      0             0                 0                0   \n",
       "3                      0             0                 0                0   \n",
       "4                      0             0                 0                0   \n",
       "...                  ...           ...               ...              ...   \n",
       "17875                  0             0                 0                0   \n",
       "17876                  0             0                 0                0   \n",
       "17877                  0             0                 0                0   \n",
       "17878                  0             0                 0                0   \n",
       "17879                  0             0                 0                0   \n",
       "\n",
       "       Distribution  Science  Training  Purchasing  Legal  fraudulent  \n",
       "0                 0        0         0           0      0           0  \n",
       "1                 0        0         0           0      0           0  \n",
       "2                 0        0         0           0      0           0  \n",
       "3                 0        0         0           0      0           0  \n",
       "4                 0        0         0           0      0           0  \n",
       "...             ...      ...       ...         ...    ...         ...  \n",
       "17875             0        0         0           0      0           0  \n",
       "17876             0        0         0           0      0           0  \n",
       "17877             0        0         0           0      0           0  \n",
       "17878             0        0         0           0      0           0  \n",
       "17879             0        0         0           0      0           0  \n",
       "\n",
       "[17880 rows x 68 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CleanDf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fb8685-233f-4d90-9201-3ba48ebf86b8",
   "metadata": {},
   "source": [
    "## Vectorize \n",
    "The description should contain very much detail, we will need to vectorize it. One possible solution is TF-idf vectorization, but this method will calculate the frequency only while ignoring the connection between words during NLP processing. I prefer to use tensorflow Tokenizer to vectorize description to catch words order infomation. Preparing for a LSTM network analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e346864b-4cd3-468d-93cd-6d66359f5c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has_company_logo    0\n",
      "has_questions       0\n",
      "fraudulent          0\n",
      "text                0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_company_logo</th>\n",
       "      <th>has_questions</th>\n",
       "      <th>fraudulent</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Marketing Intern Marketing We're Food52, and w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Customer Service - Cloud Video Production Succ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Commissioning Machinery Assistant (CMA)  Valor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Account Executive - Washington DC Sales Our pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Bill Review Manager  SpotSource Solutions LLC ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   has_company_logo  has_questions  fraudulent  \\\n",
       "0                 1              0           0   \n",
       "1                 1              0           0   \n",
       "2                 1              0           0   \n",
       "3                 1              0           0   \n",
       "4                 1              1           0   \n",
       "\n",
       "                                                text  \n",
       "0  Marketing Intern Marketing We're Food52, and w...  \n",
       "1  Customer Service - Cloud Video Production Succ...  \n",
       "2  Commissioning Machinery Assistant (CMA)  Valor...  \n",
       "3  Account Executive - Washington DC Sales Our pa...  \n",
       "4  Bill Review Manager  SpotSource Solutions LLC ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['title'] + \" \" + df['department'] + \\\n",
    "             \" \" + df['company_profile'] + \" \" + \\\n",
    "             df['description'] + \" \" + \\\n",
    "             df['requirements'] + \" \" +\\\n",
    "             df['benefits'] + \" \" +\\\n",
    "             df['function'] + \" \" +\\\n",
    "             df['required_experience']+ \" \"+\\\n",
    "             df[\"required_education\"]+ \" \" +\\\n",
    "             df[\"industry\"]\n",
    "df_last = df.drop(columns = ['job_id','title','location','department', 'telecommuting',\n",
    "                             'salary_range','company_profile','description','requirements','benefits','employment_type',\n",
    "                             'required_experience','required_education','industry','function'])\n",
    "print(df_last.isna().sum())\n",
    "df_last.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6e29474-9d14-46bf-a4cb-83cf6e358aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_clean():\n",
    "    text_list = []\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('omw-1.4')\n",
    "    for text in df_last.text:\n",
    "        text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "        text = text.lower()\n",
    "        text = text.strip()\n",
    "        text = nltk.word_tokenize(text)\n",
    "        text = [word for word in text if not word in set(stopwords.words(\"english\"))] # dropping stopwords\n",
    "        lemma = nltk.WordNetLemmatizer()\n",
    "        text = [lemma.lemmatize(word) for word in text]\n",
    "        text = \" \".join(text)\n",
    "        text = text.replace('  ',' ')\n",
    "        text_list.append(text)\n",
    "    dfData = pd.DataFrame()\n",
    "    dfData['data'] = text_list\n",
    "    dfData['target'] = df['fraudulent']\n",
    "    dfData.to_csv('washtext.csv')\n",
    "if exists('./washtext.csv'): dfData = pd.read_csv('washtext.csv')\n",
    "else: dfData = text_clean()\n",
    "dfData = dfData[['data','target']]\n",
    "text_list = dfData['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fed01505-1533-49ab-8e9a-fbe2237a6a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>marketing intern marketing food created ground...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>customer service cloud video production succes...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>commissioning machinery assistant cma valor se...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>account executive washington dc sale passion i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bill review manager spotsource solution llc gl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17875</th>\n",
       "      <td>account director distribution sale vend lookin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17876</th>\n",
       "      <td>payroll accountant accounting weblinc e commer...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17877</th>\n",
       "      <td>project cost control staff engineer cost contr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17878</th>\n",
       "      <td>graphic designer nemsia studio looking experie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17879</th>\n",
       "      <td>web application developer engineering vend loo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17880 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    data  target\n",
       "0      marketing intern marketing food created ground...       0\n",
       "1      customer service cloud video production succes...       0\n",
       "2      commissioning machinery assistant cma valor se...       0\n",
       "3      account executive washington dc sale passion i...       0\n",
       "4      bill review manager spotsource solution llc gl...       0\n",
       "...                                                  ...     ...\n",
       "17875  account director distribution sale vend lookin...       0\n",
       "17876  payroll accountant accounting weblinc e commer...       0\n",
       "17877  project cost control staff engineer cost contr...       0\n",
       "17878  graphic designer nemsia studio looking experie...       0\n",
       "17879  web application developer engineering vend loo...       0\n",
       "\n",
       "[17880 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1730a22-f37d-49bf-a293-832776dfe7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./tokinezer_file']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features = 10000\n",
    "max_vecLen = max([len(i.split(' ')) for i in dfData['data']])\n",
    "t = Tokenizer(num_words = max_features)\n",
    "# fit the tokenizer on the documents\n",
    "t.fit_on_texts(text_list)\n",
    "encoded_docs = t.texts_to_sequences(text_list)\n",
    "joblib.dump(t, './tokinezer_file') # For future Use, if we have more instances coming.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82344f0c-77bd-47de-900b-c920ca35f4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...  132   26  667]\n",
      " [   0    0    0 ...  580   26  280]\n",
      " [   0    0    0 ...  568   24 1515]\n",
      " ...\n",
      " [   0    0    0 ...   10  646   11]\n",
      " [   0    0    0 ...   57  869   28]\n",
      " [   0    0    0 ...   27  122   36]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17880, 1426)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_docs=pad_sequences(encoded_docs,padding='pre',maxlen=max_vecLen)\n",
    "print(embedded_docs)# all reviews must be same lenght. we equals all reviews lenght\n",
    "embedded_docs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678ffe7b-04ba-487a-8b0e-c5250b5a61ba",
   "metadata": {},
   "source": [
    "## Data Integration and Split\n",
    "We will unite all data we have, split into train test set. then we use train set to produce a LSTM Network and get it's prediction to the whole set, use this as a parameter to out SVM or ANN followed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a316182e-93c5-4f22-85b0-b61246b142e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWhole = CleanDf\n",
    "dfWhole['text'] = text_list\n",
    "WholeX = dfWhole.drop('fraudulent',axis = 1)\n",
    "WholeY = dfWhole['fraudulent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a47a8cc-695c-4555-a37f-b3084ff504c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_w, x_test_w, y_train, y_test = train_test_split(WholeX, WholeY, test_size= 0.1, random_state= 1)\n",
    "# print(x_train.shape, x_test.shape, y_train.shape, y_test.shape, sum(y_train), sum(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08df016b-ee45-4530-9615-307fd11f7e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(t.texts_to_sequences(x_train_w['text']),padding='pre',maxlen=max_vecLen) # for text\n",
    "x_test = pad_sequences(t.texts_to_sequences(x_test_w['text']),padding='pre',maxlen=max_vecLen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dda3945-8245-4e8a-a33c-57fe8c38736f",
   "metadata": {},
   "source": [
    "## LSTM Network analysis\n",
    "those \"data\" vectors are transformed text while keeping the original data order. Different length of that will result in a empty training prefix \"0\". Therefore those data are ready for Long Short Term Memory network analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5bcf533e-51d0-41e3-a693-590e0ec2e076",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-10 14:36:49.001179: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1426, 40)          400000    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 40)               9760      \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 41        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 409,801\n",
      "Trainable params: 409,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_vector_features=40\n",
    "model1=Sequential()\n",
    "model1.add(Embedding(max_features,embedding_vector_features,input_length=max_vecLen))\n",
    "model1.add(Bidirectional(LSTM(20)))\n",
    "model1.add(Dense(1,activation='sigmoid'))\n",
    "model1.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c92e69a-ba2e-4631-91ed-af3bf19d41cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "252/252 [==============================] - ETA: 0s - loss: 0.2067 - accuracy: 0.9480"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./bidirectional_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./bidirectional_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252/252 [==============================] - 120s 465ms/step - loss: 0.2067 - accuracy: 0.9480 - val_loss: 0.1212 - val_accuracy: 0.9603\n",
      "Epoch 2/4\n",
      "252/252 [==============================] - ETA: 0s - loss: 0.0831 - accuracy: 0.9758"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./bidirectional_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./bidirectional_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252/252 [==============================] - 122s 485ms/step - loss: 0.0831 - accuracy: 0.9758 - val_loss: 0.1007 - val_accuracy: 0.9743\n",
      "Epoch 3/4\n",
      "252/252 [==============================] - ETA: 0s - loss: 0.0485 - accuracy: 0.9868"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./bidirectional_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./bidirectional_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252/252 [==============================] - 118s 467ms/step - loss: 0.0485 - accuracy: 0.9868 - val_loss: 0.0996 - val_accuracy: 0.9737\n",
      "Epoch 4/4\n",
      "252/252 [==============================] - 108s 428ms/step - loss: 0.0289 - accuracy: 0.9929 - val_loss: 0.1114 - val_accuracy: 0.9670\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "cp = ModelCheckpoint(\"./bidirectional_model/\" ,save_best_only = True)## creaitng model checkpoint\n",
    "hist = model1.fit(x_train, y_train, epochs = 4, batch_size = 64,  callbacks = cp, validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27c5f150-ab88-4928-a3d3-4e6d4270c4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set:\n",
      "56/56 [==============================] - 4s 63ms/step\n",
      "Accuracy Score: 0.9737136465324385\n",
      "Recall Score: 0.5764705882352941\n",
      "f1 Score: 0.6758620689655171\n",
      "\n",
      " Train set:\n",
      "503/503 [==============================] - 32s 64ms/step\n",
      "Accuracy Score: 0.993661446681581\n",
      "Recall Score: 0.9014084507042254\n",
      "f1 Score: 0.9324503311258279\n"
     ]
    }
   ],
   "source": [
    "def eval_metrics(actual, prediction):\n",
    "    print(\"Accuracy Score: {}\".format(accuracy_score(actual, prediction)))\n",
    "    print(\"Recall Score: {}\".format(recall_score(actual, prediction)))\n",
    "    print(\"f1 Score: {}\".format(f1_score(actual, prediction)))\n",
    "print(\"Test set:\")\n",
    "model1 = load_model(\"./bidirectional_model/\")\n",
    "pred = model1.predict(x_test)\n",
    "pred = (pred >= 0.5)\n",
    "eval_metrics(y_test, pred)\n",
    "print(\"\\n Train set:\")\n",
    "predTrain = model1.predict(x_train)\n",
    "predTrain = (predTrain >= 0.5)\n",
    "eval_metrics(y_train, predTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20b58f4-6699-4bea-a0fc-01630325f741",
   "metadata": {},
   "source": [
    "## SVM Predict\n",
    "we get a SVM as the last step predicting, see if we can get higher f1 score by this.\n",
    "This SVM will use kernel we choose to optimize the outcome, while given all parameters in our cleaned dataframe and the LSTM prediction value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ec99eac-2a5b-40d0-9b92-5dfeb8e9953d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "503/503 [==============================] - 33s 66ms/step\n",
      "56/56 [==============================] - 4s 63ms/step\n"
     ]
    }
   ],
   "source": [
    "x = CleanDf.drop([\"fraudulent\"],axis = 1)\n",
    "y = CleanDf['fraudulent']\n",
    "x_train1 = x_train_w.drop([\"text\"],axis=1)\n",
    "x_train1['LSTM'] = model1.predict(x_train)\n",
    "x_test1 = x_test_w.drop([\"text\"],axis=1)\n",
    "x_test1['LSTM'] = model1.predict(x_test)\n",
    "y_train1 = y_train\n",
    "y_test1 = y_test\n",
    "print(x_train1.shape, x_test1.shape, y_train1.shape, y_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c74e9c7-b6c1-416b-b4fd-8577bd5e4812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9776286353467561\n",
      "Recall Score: 0.5764705882352941\n",
      "f1 Score: 0.7101449275362318\n"
     ]
    }
   ],
   "source": [
    "svc=SVC(kernel='poly') \n",
    "svc.fit(x_train1,y_train1)\n",
    "y_pred=svc.predict(x_test1)\n",
    "eval_metrics(y_test1, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64b86e59-136e-4057-94a4-1f0857205b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9909271687795178\n",
      "Recall Score: 0.8220230473751601\n",
      "f1 Score: 0.8979020979020979\n"
     ]
    }
   ],
   "source": [
    "# Training score\n",
    "y_pred=svc.predict(x_train1)\n",
    "eval_metrics(y_train1, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15eb3012-ff15-4fe1-b1a6-c95d3272194c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area under curve (auc):  0.9107829298661444\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"area under curve (auc): \", metrics.roc_auc_score(y_train1, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e7c308-2991-41e5-95bc-df9552ebb2d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
